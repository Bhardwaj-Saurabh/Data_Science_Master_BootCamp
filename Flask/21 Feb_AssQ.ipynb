{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOdL8iwLR95jTiUzIWT03Dg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.**\n","\n","Web scraping is an automated method used to extract large amounts of data from websites. The data on the websites are unstructured. Web scraping helps collect these unstructured data and store it in a structured form. There are different ways to scrape websites such as online Services, APIs or writing your own code. In this article, we’ll see how to implement web scraping with python. \n","\n","The applications of web scraping:\n","\n","Price Comparison: Services such as ParseHub use web scraping to collect data from online shopping websites and use it to compare the prices of products.\n","\n","Email address gathering: Many companies that use email as a medium for marketing, use web scraping to collect email ID and then send bulk emails.\n","\n","Social Media Scraping: Web scraping is used to collect data from Social Media websites such as Twitter to find out what’s trending.\n","\n","Research and Development: Web scraping is used to collect a large set of data (Statistics, General Information, Temperature, etc.) from websites, which are analyzed and used to carry out Surveys or for R&D.\n","\n","Job listings: Details regarding job openings, interviews are collected from different websites and then listed in one place so that it is easily accessible to the user.\n","\n","Some of the main use cases of web scraping include price monitoring, price intelligence, news monitoring, lead generation, and market research."],"metadata":{"id":"Id5mxUNA7YlV"}},{"cell_type":"markdown","source":["**Q2. What are the different methods used for Web Scraping?**\n","\n","The most common techniques used for Web Scraping are\n","\n","Human copy-and-paste.\n","\n","Text pattern matching.\n","\n","HTTP programming.\n","\n","HTML parsing.\n","\n","DOM parsing.\n","\n","Vertical aggregation.\n","\n","Semantic annotation recognizing.\n","\n","Computer vision web-page analysis."],"metadata":{"id":"9w5v-XwC7Yg3"}},{"cell_type":"markdown","source":["**Q3. What is Beautiful Soup? Why is it used?**\n","\n","Beautiful Soup provides simple methods for navigating, searching, and modifying a parse tree in HTML, XML files. It transforms a complex HTML document into a tree of Python objects. It also automatically converts the document to Unicode, so you don’t have to think about encodings. \n","\n","This tool not only helps you scrape but also to clean the data. Beautiful Soup supports the HTML parser included in Python’s standard library, but it also supports several third-party Python parsers like lxml or hml5lib."],"metadata":{"id":"fvfCtawl7Yee"}},{"cell_type":"markdown","source":["**Q4. Why is flask used in this Web Scraping project?**\n","\n","Flask is used to parse our collected data and display it as HTML in a new HTML file."],"metadata":{"id":"TBh-W7aC7YcN"}},{"cell_type":"markdown","source":["**Q5. Write the names of AWS services used in this project. Also, explain the use of each service.**\n","\n","In the project, below AWS services were used. \n","- CodePipeline\n","- Elastic BeanStack\n","\n","AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates.\n","\n","\n","Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic Beanstalk automatically handles the deployment—from capacity provisioning, load balancing, and auto scaling to application health monitoring.\n","\n"],"metadata":{"id":"D2WS76P87YZu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqv8hO0a7UEw"},"outputs":[],"source":[]}]}